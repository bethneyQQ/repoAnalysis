#!/usr/bin/env bash
# åœºæ™¯â‘¢ çœŸå®æ¼”ç¤ºï¼šå›å½’æ£€æµ‹ Pass â†’ Fail â†’ Pass å¾ªç¯
# ä½¿ç”¨çœŸå®çš„ä»£ç ä¿®æ”¹è§¦å‘æµ‹è¯•å¤±è´¥

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
cd "$PROJECT_ROOT"

GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

ok() { echo -e "${GREEN}âœ” $*${NC}"; }
fail() { echo -e "${RED}âœ˜ $*${NC}"; }
info() { echo -e "${BLUE}â„¹ $*${NC}"; }

echo "========================================"
echo "ğŸ§ª åœºæ™¯â‘¢ çœŸå®æ¼”ç¤ºï¼šå›å½’æ£€æµ‹ Pass â†’ Fail â†’ Pass"
echo "========================================"
echo ""

# ç¡®ä¿æœ‰æµ‹è¯•æ–‡ä»¶
if [ ! -f "tests/test_nodes.py" ]; then
    fail "tests/test_nodes.py not found"
    exit 1
fi

# Step 1: åŸºçº¿æµ‹è¯• (åº”è¯¥ PASS)
info "Step 1: Running baseline regression test..."
python3 cli.py regression --baseline "HEAD~1" --build "HEAD" --model "claude-3-haiku-20240307" > /tmp/reg_baseline.log 2>&1

GATE_BASELINE=$(ls -t .ai-snapshots/regression_gate-*.md 2>/dev/null | head -1)
if [ -n "$GATE_BASELINE" ]; then
    if grep -qi "PASS\|pass" "$GATE_BASELINE"; then
        ok "âœ… Baseline regression: PASS"
    else
        info "Baseline result captured"
    fi
    cp "$GATE_BASELINE" /tmp/gate_baseline.md
fi

# Step 2: æ³¨å…¥çœŸå®çš„æµ‹è¯•å¤±è´¥
info "Step 2: Injecting REAL test failures..."

# å¤‡ä»½åŸå§‹æµ‹è¯•æ–‡ä»¶
cp tests/test_nodes.py tests/test_nodes.py.backup

# æ³¨å…¥ä¼šå¯¼è‡´æµ‹è¯•å¤±è´¥çš„ä»£ç 
cat >> tests/test_nodes.py << 'EOF'

# INJECTED FAILURE: This test will always fail
def test_injected_failure():
    """This test is intentionally broken to demonstrate FAIL gate"""
    assert False, "Intentional failure for regression demo"

def test_another_failure():
    """Another intentional failure"""
    assert 1 == 2, "Math is broken!"
EOF

ok "Injected 2 failing tests into tests/test_nodes.py"

# Step 3: è¿è¡Œæµ‹è¯•éªŒè¯ç¡®å®å¤±è´¥
info "Step 3: Running tests to verify failures..."
if python3 -m pytest tests/test_nodes.py -v > /tmp/pytest_fail.log 2>&1; then
    fail "Tests should have failed but passed!"
else
    FAILED_COUNT=$(grep -c "FAILED" /tmp/pytest_fail.log || echo 0)
    ok "Tests failed as expected (${FAILED_COUNT} failures)"
fi

# Step 4: è¿è¡Œå›å½’æ£€æµ‹ï¼ˆåº”è¯¥å¾—åˆ° FAILï¼‰
info "Step 4: Running regression detection (should FAIL)..."

# åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„å·®åˆ†ç¯å¢ƒæ¥è§¦å‘å¤±è´¥åˆ¤å®š
# ç”±äºæˆ‘ä»¬ä¿®æ”¹äº†æµ‹è¯•ï¼ŒæŒ‡æ ‡ä¼šå˜å·®

python3 cli.py regression --baseline "HEAD~1" --build "HEAD" --model "claude-3-haiku-20240307" > /tmp/reg_fail.log 2>&1

GATE_FAIL=$(ls -t .ai-snapshots/regression_gate-*.md 2>/dev/null | head -1)

# æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°é—®é¢˜
if [ -n "$GATE_FAIL" ]; then
    info "Generated regression gate after failures"

    # å³ä½¿LLMå¯èƒ½ä»ç„¶ç»™PASSï¼ˆå› ä¸ºå®ƒä¸çŸ¥é“çœŸå®æµ‹è¯•ç»“æœï¼‰ï¼Œæˆ‘ä»¬æ‰‹åŠ¨éªŒè¯æµ‹è¯•ç¡®å®å¤±è´¥äº†
    if [ "$FAILED_COUNT" -gt 0 ]; then
        ok "âœ… Verified: Tests are FAILING ($FAILED_COUNT failures)"
        echo "   (Note: LLM gate may still show PASS as it analyzes git diff, not live test results)"
        echo "   (In production, you would feed actual test results to LLM)"
    fi
fi

# Step 5: ä¿®å¤é—®é¢˜ï¼ˆæ¢å¤åŸå§‹æ–‡ä»¶ï¼‰
info "Step 5: Fixing issues (removing broken tests)..."
mv tests/test_nodes.py.backup tests/test_nodes.py
ok "Restored original test file"

# Step 6: éªŒè¯æµ‹è¯•æ¢å¤æ­£å¸¸
info "Step 6: Running tests to verify fix..."
if python3 -m pytest tests/test_nodes.py -v > /tmp/pytest_pass.log 2>&1; then
    ok "âœ… Tests PASSING after fix"
else
    fail "Tests should pass after fix"
fi

# Step 7: å†æ¬¡è¿è¡Œå›å½’æ£€æµ‹ï¼ˆåº”è¯¥ PASSï¼‰
info "Step 7: Running regression after fix (should PASS)..."
python3 cli.py regression --baseline "HEAD~1" --build "HEAD" --model "claude-3-haiku-20240307" > /tmp/reg_pass.log 2>&1

GATE_PASS=$(ls -t .ai-snapshots/regression_gate-*.md 2>/dev/null | head -1)
if [ -n "$GATE_PASS" ]; then
    if grep -qi "PASS\|pass" "$GATE_PASS"; then
        ok "âœ… After fix regression: PASS"
    fi
fi

echo ""
echo "========================================"
echo "ğŸ“Š æ¼”ç¤ºæ€»ç»“"
echo "========================================"
echo "âœ… Step 1: Baseline test (gate generated)"
echo "âœ… Step 2: Injected 2 failing tests into tests/test_nodes.py"
echo "âœ… Step 3: Verified tests FAILED (${FAILED_COUNT} failures)"
echo "âœ… Step 4: Ran regression detection with failures"
echo "âœ… Step 5: Removed failing tests"
echo "âœ… Step 6: Verified tests PASS after fix"
echo "âœ… Step 7: Regression detection after fix"
echo ""
echo "ğŸ¯ åœºæ™¯â‘¢ éªŒè¯ï¼šçœŸå®çš„ Pass â†’ Fail â†’ Pass å¾ªç¯å®Œæˆ"
echo ""
echo "Test logs:"
echo "  - /tmp/pytest_fail.log (should show FAILED tests)"
echo "  - /tmp/pytest_pass.log (should show all passing)"
echo "========================================"
