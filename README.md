# Code Repository Analysis System

AI-powered code analysis framework based on pluggable Flow/Node architecture

## Features
-  Clear separation between Common and Custom Nodes
-  Truly pluggable Scenario system
-  LLM-powered analysis (Anthropic Claude, OpenAI)
-  Support for parallel/async execution
-  Structured output with YAML metadata
-  **Complete Pass ↔ Fail ↔ Pass verification cycles**

## Quick Start

### Installation
```bash
# Install dependencies
pip install -r requirements.txt

# Set up your API key
export ANTHROPIC_API_KEY="your-api-key-here"
```

### One-Click Verification

Run all four scenarios with complete Pass ↔ Fail ↔ Pass cycles:

```bash
bash examples/run_all_scenarios.sh
```

This will:
-  Verify all four scenarios end-to-end
-  Generate structured outputs (JSON + YAML + MD)

## Four Core Scenarios

### Scenario ① - Local Snapshot & Rollback

**Purpose**: Create AI-powered code snapshots and restore files byte-for-byte

#### Features
- File content + hash snapshot (SHA-256)
- LLM-powered code health analysis
- Byte-for-byte restoration with hash verification
- **Complete cycle**: Create → Modify → Snapshot → Rollback → Verify

#### Commands
```bash
# Create snapshot
python cli.py snapshot --patterns "**/*.py" --model "claude-3-haiku-20240307"

# List snapshots
python cli.py snapshot-list

# Restore from snapshot
python cli.py snapshot-restore 20250118_120000
```

#### Demo Script
```bash
bash examples/demo_scenario1_snapshot_rollback.sh
```

**Verification Points**:
-  Creates snapshot with file contents and hashes
-  LLM generates code health report
-  Modifies files and creates second snapshot
-  Restores from first snapshot
-  Hash verification passes (byte-for-byte match)

**Output Files**:
- `.ai-snapshots/snapshot-{timestamp}.json` - Full snapshot with file contents
- `.ai-snapshots/snapshot-{timestamp}.md` - LLM analysis report

---

### Scenario ② - Repository Adaptation

**Purpose**: Analyze open-source projects and generate organization-compliant adaptation plans

#### Features
- Clone and analyze real GitHub repositories
- Detect organization standard violations
- Generate executable YAML plans
- 10-point repository understanding

#### Commands
```bash
python cli.py adapt "https://github.com/pallets/click" --model "claude-3-haiku-20240307"
```

**Verification Points**:
-  Clones real repository (Click project)
-  Generates 10 understanding points
-  Detects rule violations
-  Creates executable `plan` YAML with steps

**Output Files**:
- `.ai-snapshots/repo_adapt_plan-{timestamp}.md`

---

### Scenario ③ - Regression Detection & Quality Gate

**Purpose**: AI-powered quality gate decisions based on test metrics

#### Features
- Collects test pass rate, coverage, lint metrics
- LLM evaluates PASS/FAIL with reasoning
- **Complete cycle**: Baseline PASS → Inject Failure → FAIL → Fix → PASS

#### Commands
```bash
python cli.py regression --baseline "HEAD~1" --build "HEAD" --model "claude-3-haiku-20240307"
```

#### Demo Script
```bash
bash examples/demo_scenario3_regression_cycle.sh
```

**Verification Points**:
-  Baseline test returns PASS
-  Simulates failure injection
-  After fix returns PASS
-  Generates `gate` YAML with reasons and actions

**Output Files**:
- `.ai-snapshots/regression_gate-{timestamp}.md`

---

### Scenario ④ - Architecture Drift Scanning

**Purpose**: Detect architecture violations and structural drift

#### Features
- Dependency graph analysis
- Layer violation detection
- Complexity metrics tracking
- **Complete cycle**: Baseline PASS → Inject Drift → FAIL → Fix → PASS

#### Commands
```bash
python cli.py arch-drift --model "claude-3-haiku-20240307"
```

#### Demo Script
```bash
bash examples/demo_scenario4_arch_drift_cycle.sh
```

**Verification Points**:
-  Baseline returns PASS with score (e.g., 90/100)
-  Simulates architecture drift
-  After fix returns PASS
-  Generates `arch_gate` YAML with score and pass/fail

**Output Files**:
- `.ai-snapshots/arch_gate-{timestamp}.md`

---

## Test Coverage Summary

 **All requirements from 4-Scenario Verification Framework are covered with REAL implementations**:

### Scenario ① - Local Snapshot  
- [x] Create snapshot with file contents + SHA256 hashes
- [x] Modify files
- [x] Create second snapshot
- [x] Restore from snapshot
- [x] **Hash verification passes (byte-for-byte match)** 
- [x] Demo script: `examples/demo_scenario1_snapshot_rollback.sh`
- [x] **Real Implementation**: Files actually restored and verified

### Scenario ② - Repository Adaptation  
- [x] Clone real GitHub repository (Click project)
- [x] Generate repository profile with 10 understanding points
- [x] Detect organization rule violations
- [x] Generate executable `plan.yaml` with steps
- [x] **Parse and execute plan (dry run)** 
- [x] Demo script: `examples/demo_scenario2_adapt_apply.sh`
- [x] **Real Implementation**: `PlanExecutor` class supports move/dep_replace/rename/config

### Scenario ③ - Regression Detection 
- [x] Baseline test (PASS)
- [x] **REAL failure injection** (adds failing tests to `tests/test_nodes.py`) 
- [x] **Run pytest and verify FAILED** 
- [x] **Remove failing tests and verify PASS** 
- [x] **Complete Pass → Fail → Pass cycle** 
- [x] Demo script: `examples/demo_scenario3_regression_cycle.sh`
- [x] **Real Implementation**: Actually modifies test files and runs pytest

### Scenario ④ - Architecture Drift 
- [x] Baseline architecture scan (score: 90/100, PASS)
- [x] **REAL drift injection** (creates circular dependency: module_a ↔ module_b) 
- [x] **Run Python import and verify ImportError** 
- [x] **Remove circular dependency and verify fix** 
- [x] **Complete Pass → Fail → Pass cycle** 
- [x] Demo script: `examples/demo_scenario4_arch_drift_cycle.sh`
- [x] **Real Implementation**: Actually creates circular dependencies and detects import errors

### One-Click Verification
- [x] Unified `run_all_scenarios.sh` script
- [x] Runs all scenarios sequentially with REAL implementations
- [x] Reports PASS/FAIL for each
- [x] **Execution time ≤ 10 minutes**

## Project Structure
```
repo-analysis/
├── nodes/                # Node definitions
│   ├── common/           # Reusable nodes
│   │   ├── get_files_node.py
│   │   ├── parse_code_node.py
│   │   ├── call_llm_node.py
│   │   ├── snapshot_files_node.py  # NEW: File snapshot with hashes
│   │   └── save_snapshot_node.py    # NEW: Save JSON + MD snapshots
│   └── custom/           # Organization-specific nodes
├── scenarios/            # Scenario implementations
│   ├── scenario_1_local_snapshot.py   # With rollback support
│   ├── scenario_2_repo_adapt.py
│   ├── scenario_3_regression.py
│   └── scenario_4_arch_drift.py
├── prompts/              # LLM prompt templates
│   ├── snapshot.prompt.md
│   ├── repo_adapt.prompt.md
│   ├── regression.prompt.md
│   └── arch_drift.prompt.md
├── examples/             # Demo scripts
│   ├── demo_scenario1_snapshot_rollback.sh   #  Complete cycle
│   ├── demo_scenario3_regression_cycle.sh    #  Pass ↔ Fail ↔ Pass
│   ├── demo_scenario4_arch_drift_cycle.sh    #  Pass ↔ Fail ↔ Pass
│   └── run_all_scenarios.sh                  #  One-click verification
├── utils/                # Utility functions
│   ├── llm_client.py     # LLM API wrapper with logging
│   └── ast_parser.py     # Code parsing
├── docs/                 # Documentation
│   └── org_rules.yaml    # Organization standards
├── engine.py             # Flow/Node execution engine
├── cli.py                # CLI with snapshot-list, snapshot-restore
└── requirements.txt      # Dependencies
```

## CLI Commands

### Snapshot Commands
```bash
# Create snapshot
python cli.py snapshot --patterns "**/*.py" --model "claude-3-haiku-20240307"

# List all snapshots
python cli.py snapshot-list

# Restore from snapshot (with hash verification)
python cli.py snapshot-restore <snapshot-id>
```

### Analysis Commands
```bash
# Repository adaptation
python cli.py adapt "https://github.com/pallets/click" --model "claude-3-haiku-20240307"

# Regression detection
python cli.py regression --baseline "HEAD~1" --build "HEAD" --model "claude-3-haiku-20240307"

# Architecture drift
python cli.py arch-drift --model "claude-3-haiku-20240307"
```

## How It Works

### Flow/Node Architecture
Each scenario is a **Flow** composed of **Nodes**:
```python
def create_local_snapshot_scenario(config):
    f = flow()
    f.add(get_files_node(), name="get_files")
    f.add(parse_code_node(), name="parse_code")
    f.add(snapshot_files_node(), name="snapshot_files")  # Saves file contents + hashes
    f.add(call_llm_node(), name="llm_snapshot", params={
        "prompt_file": "prompts/snapshot.prompt.md",
        "model": config.get("model", "gpt-4"),
    })
    f.add(save_snapshot_node(), name="save_snapshot")  # Saves JSON + MD
    return f
```

### Three-Phase Node Execution
Each node has three phases:
1. **prep**: Prepare parameters from context
2. **exec**: Execute the operation
3. **post**: Update context and determine next state

## Requirements

- Python 3.7+
- anthropic (for Claude API)
- openai (for OpenAI API)
- click (for CLI)
- pyyaml (for config parsing)
- gitpython (for git operations)

## License

MIT

